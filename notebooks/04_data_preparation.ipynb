{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a29e1a",
   "metadata": {},
   "source": [
    "# STEP 4 - Fraud_Detection - Data Preparation & Entity Behavioral Risk Encoding\n",
    "\n",
    "### Objective:\n",
    "- Prepare data for modeling with fraud-specific behavioral intelligence\n",
    "- No target leakage (frequency encoding uses NO target info)\n",
    "- Optimize memory & ensure zero NaNs before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45e931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5153e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4A: Dataset Loaded\n",
      "============================================================\n",
      "Dataset shape: (590540, 458)\n",
      "\n",
      "Target distribution:\n",
      "isFraud\n",
      "0    0.96501\n",
      "1    0.03499\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4A: Load Feature-Engineered Dataset\n",
    "# ============================================================\n",
    "\n",
    "train = pd.read_parquet(\"../data/processed/train_features_v1.parquet\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4A: Dataset Loaded\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Dataset shape:\", train.shape)\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train[\"isFraud\"].value_counts(normalize=True))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15dd09d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4B: Feature Groups Defined\n",
      "============================================================\n",
      "Numeric features: 403\n",
      "Categorical features: 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4B: Define Feature Groups\n",
    "# ============================================================\n",
    "\n",
    "TARGET = \"isFraud\"\n",
    "\n",
    "numeric_cols = train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_cols = train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "if TARGET in numeric_cols:\n",
    "    numeric_cols.remove(TARGET)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4B: Feature Groups Defined\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Numeric features: {len(numeric_cols)}\")\n",
    "print(f\"Categorical features: {len(categorical_cols)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943ecba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4C: Frequency Encoding SKIPPED\n",
      "============================================================\n",
      "‚ö†Ô∏è  CRITICAL: Frequency features will be calculated in Step 5\n",
      "    AFTER train/valid split to prevent data leakage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4C: FREQUENCY ENCODING REMOVED (MOVED TO STEP 5)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4C: Frequency Encoding SKIPPED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚ö†Ô∏è  CRITICAL: Frequency features will be calculated in Step 5\")\n",
    "print(\"    AFTER train/valid split to prevent data leakage\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77dc1b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4D: Type Optimization\n",
      "============================================================\n",
      "‚úì Memory reduced: 2540.50 MB ‚Üí 1632.65 MB\n",
      "  (35.7% reduction)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4D: Type Optimization\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4D: Type Optimization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "memory_before = train.memory_usage(deep=True).sum() / 1024**2\n",
    "\n",
    "# Float64 ‚Üí Float32\n",
    "float_cols = train.select_dtypes(include=[\"float64\"]).columns\n",
    "for col in float_cols:\n",
    "    train[col] = train[col].astype(\"float32\")\n",
    "\n",
    "# Int64 ‚Üí Int32\n",
    "int_cols = train.select_dtypes(include=[\"int64\"]).columns\n",
    "for col in int_cols:\n",
    "    if col != TARGET:\n",
    "        train[col] = train[col].astype(\"int32\")\n",
    "\n",
    "memory_after = train.memory_usage(deep=True).sum() / 1024**2\n",
    "\n",
    "print(f\"‚úì Memory reduced: {memory_before:.2f} MB ‚Üí {memory_after:.2f} MB\")\n",
    "print(f\"  ({100 * (1 - memory_after/memory_before):.1f}% reduction)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4bca2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4E: Feature Summary\n",
      "============================================================\n",
      "Numeric features: 404\n",
      "Categorical features: 32\n",
      "Total features: 458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4E: Updated Feature Summary\n",
    "# ============================================================\n",
    "\n",
    "numeric_cols_updated = train.select_dtypes(include=[\"int32\", \"int64\", \"float32\", \"float64\"]).columns.tolist()\n",
    "categorical_cols_updated = train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "if TARGET in numeric_cols_updated:\n",
    "    numeric_cols_updated.remove(TARGET)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4E: Feature Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Numeric features: {len(numeric_cols_updated)}\")\n",
    "print(f\"Categorical features: {len(categorical_cols_updated)}\")\n",
    "print(f\"Total features: {train.shape[1]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f00816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4F: Final Safety Imputation\n",
      "============================================================\n",
      "Missing values before imputation: 115,523,073\n",
      "Missing values after imputation: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4F: FINAL SAFETY IMPUTATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4F: Final Safety Imputation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_before = train.isna().sum().sum()\n",
    "print(f\"Missing values before imputation: {missing_before:,}\")\n",
    "\n",
    "# Numeric imputation\n",
    "for col in numeric_cols_updated:\n",
    "    if train[col].isna().any():\n",
    "        train[col] = train[col].fillna(train[col].median())\n",
    "\n",
    "# Categorical imputation\n",
    "for col in categorical_cols_updated:\n",
    "    if train[col].isna().any():\n",
    "        train[col] = train[col].fillna(\"Unknown\")\n",
    "\n",
    "missing_after = train.isna().sum().sum()\n",
    "print(f\"Missing values after imputation: {missing_after:,}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fafe122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4G: Final Dataset Validation\n",
      "============================================================\n",
      "Final dataset shape: (590540, 458)\n",
      "Remaining missing values: 0\n",
      "Memory usage: 2065.39 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4G: Final Dataset Validation\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4G: Final Dataset Validation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final dataset shape: {train.shape}\")\n",
    "print(f\"Remaining missing values: {train.isna().sum().sum()}\")\n",
    "print(f\"Memory usage: {train.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7749ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4H: Dataset Saved\n",
      "============================================================\n",
      "‚úì Saved to: ../data/processed/train_features_v2.parquet\n",
      "‚úì Shape: (590540, 458)\n",
      "‚úì Ready for modeling (frequency encoding in Step 5)\n",
      "============================================================\n",
      "\n",
      "üéØ Step 4 completed successfully!\n",
      "   Next: Step 5 - Model Training (with proper frequency encoding)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 4H: Save Prepared Dataset\n",
    "# ============================================================\n",
    "\n",
    "output_path = \"../data/processed/train_features_v2.parquet\"\n",
    "train.to_parquet(output_path, index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4H: Dataset Saved\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úì Saved to: {output_path}\")\n",
    "print(f\"‚úì Shape: {train.shape}\")\n",
    "print(f\"‚úì Ready for modeling (frequency encoding in Step 5)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüéØ Step 4 completed successfully!\")\n",
    "print(\"   Next: Step 5 - Model Training (with proper frequency encoding)\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
