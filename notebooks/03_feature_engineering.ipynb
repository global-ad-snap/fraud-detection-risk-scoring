{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c214df5",
   "metadata": {},
   "source": [
    "# STEP 3 â€” FEATURE ENGINEERING\n",
    "### Objective:\n",
    "- Create fraud-specific behavioral features\n",
    "- Transform raw data into predictive signals\n",
    "- NO target leakage (no group-by with isFraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cadc030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec72589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3A: Dataset Loaded\n",
      "============================================================\n",
      "Dataset shape: (590540, 434)\n",
      "\n",
      "Target distribution:\n",
      "isFraud\n",
      "0    0.96501\n",
      "1    0.03499\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3A: Load Cleaned Dataset (from Step 2)\n",
    "\n",
    "\n",
    "train = pd.read_parquet(\"../data/raw/train_merged.parquet\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3A: Dataset Loaded\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset shape: {train.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train[\"isFraud\"].value_counts(normalize=True))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5304e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3B: Transaction Amount Features\n",
      "============================================================\n",
      "âœ“ Created 3 transaction amount features\n",
      "\n",
      "Amount Distribution:\n",
      "       TransactionAmt  log_transaction_amt\n",
      "count   590540.000000        590540.000000\n",
      "mean       135.027176             4.382960\n",
      "std        239.162522             0.937183\n",
      "min          0.251000             0.223943\n",
      "25%         43.321000             3.791459\n",
      "50%         68.769000             4.245190\n",
      "75%        125.000000             4.836282\n",
      "max      31937.391000            10.371564\n",
      "\n",
      "Extreme Value Proportions:\n",
      "  Low amount (â‰¤10th percentile): 10.08%\n",
      "  High amount (â‰¥90th percentile): 10.00%\n",
      "\n",
      "Fraud Rate by Amount Category:\n",
      "  Low amount: 5.59%\n",
      "  High amount: 5.10%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3B: Transaction Amount Features\n",
    "# Log transformation handles skewness\n",
    "# Threshold flags capture extreme values\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3B: Transaction Amount Features\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Log transformation (handles skewed distribution)\n",
    "train[\"log_transaction_amt\"] = np.log1p(train[\"TransactionAmt\"])\n",
    "\n",
    "# Extreme value flags\n",
    "q10 = train[\"TransactionAmt\"].quantile(0.10)\n",
    "q90 = train[\"TransactionAmt\"].quantile(0.90)\n",
    "\n",
    "train[\"is_low_amt\"] = (train[\"TransactionAmt\"] <= q10).astype(\"int8\")\n",
    "train[\"is_high_amt\"] = (train[\"TransactionAmt\"] >= q90).astype(\"int8\")\n",
    "\n",
    "print(\"âœ“ Created 3 transaction amount features\")\n",
    "print(f\"\\nAmount Distribution:\")\n",
    "print(train[[\"TransactionAmt\", \"log_transaction_amt\"]].describe())\n",
    "print(f\"\\nExtreme Value Proportions:\")\n",
    "print(f\"  Low amount (â‰¤10th percentile): {train['is_low_amt'].mean():.2%}\")\n",
    "print(f\"  High amount (â‰¥90th percentile): {train['is_high_amt'].mean():.2%}\")\n",
    "print()\n",
    "\n",
    "# Fraud rate validation\n",
    "print(\"Fraud Rate by Amount Category:\")\n",
    "print(f\"  Low amount: {train[train['is_low_amt']==1]['isFraud'].mean():.2%}\")\n",
    "print(f\"  High amount: {train[train['is_high_amt']==1]['isFraud'].mean():.2%}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982b751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3C: Card Features\n",
      "============================================================\n",
      "âœ“ Created 4 card features\n",
      "\n",
      "Card Presence Rates:\n",
      "  card2: 98.49%\n",
      "  card3: 99.73%\n",
      "  card5: 99.28%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3C: Card Features\n",
    "# Card combinations detect reused/compromised cards\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3C: Card Features\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Card combination (composite key)\n",
    "train[\"card_combo\"] = (\n",
    "    train[\"card1\"].astype(str) + \"_\" +\n",
    "    train[\"card2\"].astype(str) + \"_\" +\n",
    "    train[\"card3\"].astype(str)\n",
    ")\n",
    "\n",
    "# Card type flags\n",
    "train[\"has_card2\"] = train[\"card2\"].notna().astype(\"int8\")\n",
    "train[\"has_card3\"] = train[\"card3\"].notna().astype(\"int8\")\n",
    "train[\"has_card5\"] = train[\"card5\"].notna().astype(\"int8\")\n",
    "\n",
    "print(\"âœ“ Created 4 card features\")\n",
    "print(f\"\\nCard Presence Rates:\")\n",
    "print(f\"  card2: {train['has_card2'].mean():.2%}\")\n",
    "print(f\"  card3: {train['has_card3'].mean():.2%}\")\n",
    "print(f\"  card5: {train['has_card5'].mean():.2%}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3deb481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3D: Address Features\n",
      "============================================================\n",
      "âœ“ Created 1 address feature\n",
      "  Address mismatch rate: 88.87%\n",
      "  Fraud rate when mismatch: 2.46%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3D: Address Features\n",
    "# Address matching detects shipping fraud\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3D: Address Features\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Address mismatch (billing â‰  shipping)\n",
    "train[\"addr_mismatch\"] = (\n",
    "    (train[\"addr1\"] != train[\"addr2\"]) & \n",
    "    train[\"addr1\"].notna() & \n",
    "    train[\"addr2\"].notna()\n",
    ").astype(\"int8\")\n",
    "\n",
    "print(\"âœ“ Created 1 address feature\")\n",
    "print(f\"  Address mismatch rate: {train['addr_mismatch'].mean():.2%}\")\n",
    "print(f\"  Fraud rate when mismatch: {train[train['addr_mismatch']==1]['isFraud'].mean():.2%}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c22ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3E: Device Features\n",
      "============================================================\n",
      "âœ“ Created 2 device features\n",
      "  DeviceType present: 23.84%\n",
      "  DeviceInfo present: 20.09%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3E: Device Features\n",
    "# Device type presence indicates device fingerprinting\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3E: Device Features\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Device presence flags\n",
    "train[\"has_device_type\"] = train[\"DeviceType\"].notna().astype(\"int8\")\n",
    "train[\"has_device_info\"] = train[\"DeviceInfo\"].notna().astype(\"int8\")\n",
    "\n",
    "print(\"âœ“ Created 2 device features\")\n",
    "print(f\"  DeviceType present: {train['has_device_type'].mean():.2%}\")\n",
    "print(f\"  DeviceInfo present: {train['has_device_info'].mean():.2%}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b02f243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3F: Email & Domain Features\n",
      "============================================================\n",
      "âœ“ Created 3 email features\n",
      "  P_email present: 84.01%\n",
      "  R_email present: 23.25%\n",
      "  Email domains match: 17.36%\n",
      "\n",
      "Fraud rate when emails match: 9.65%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3F: Email & Domain Features\n",
    "# Email presence/matching detects account fraud\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3F: Email & Domain Features\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Email presence\n",
    "train[\"has_P_email\"] = train[\"P_emaildomain\"].notna().astype(\"int8\")\n",
    "train[\"has_R_email\"] = train[\"R_emaildomain\"].notna().astype(\"int8\")\n",
    "\n",
    "# Email domain matching\n",
    "train[\"email_domain_match\"] = (\n",
    "    (train[\"P_emaildomain\"] == train[\"R_emaildomain\"]) &\n",
    "    train[\"P_emaildomain\"].notna() &\n",
    "    train[\"R_emaildomain\"].notna()\n",
    ").astype(\"int8\")\n",
    "\n",
    "print(\"âœ“ Created 3 email features\")\n",
    "print(f\"  P_email present: {train['has_P_email'].mean():.2%}\")\n",
    "print(f\"  R_email present: {train['has_R_email'].mean():.2%}\")\n",
    "print(f\"  Email domains match: {train['email_domain_match'].mean():.2%}\")\n",
    "print(f\"\\nFraud rate when emails match: {train[train['email_domain_match']==1]['isFraud'].mean():.2%}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c1d01b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3G: Identity Features\n",
      "============================================================\n",
      "âœ“ Created 2 identity aggregation features\n",
      "\n",
      "Identity Feature Statistics:\n",
      "       identity_feature_count  identity_missing_ratio\n",
      "count           590540.000000           590540.000000\n",
      "mean                 5.767157                0.848233\n",
      "std                 10.436908                0.274655\n",
      "min                  0.000000                0.000000\n",
      "25%                  0.000000                1.000000\n",
      "50%                  0.000000                1.000000\n",
      "75%                  0.000000                1.000000\n",
      "max                 38.000000                1.000000\n",
      "\n",
      "Fraud vs Non-Fraud Comparison:\n",
      "         identity_feature_count  identity_missing_ratio\n",
      "isFraud                                                \n",
      "0                      5.510649                0.854983\n",
      "1                     12.841553                0.662064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3G: Identity Feature Aggregations\n",
    "# Identity completeness signals verification quality\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3G: Identity Features\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "identity_cols = [c for c in train.columns if c.startswith(\"id_\")]\n",
    "\n",
    "# Count non-null identity features\n",
    "train[\"identity_feature_count\"] = train[identity_cols].notna().sum(axis=1).astype(\"int8\")\n",
    "\n",
    "# Missing ratio\n",
    "train[\"identity_missing_ratio\"] = (\n",
    "    train[identity_cols].isna().sum(axis=1) / len(identity_cols)\n",
    ").astype(\"float32\")\n",
    "\n",
    "print(f\"âœ“ Created 2 identity aggregation features\")\n",
    "print(f\"\\nIdentity Feature Statistics:\")\n",
    "print(train[[\"identity_feature_count\", \"identity_missing_ratio\"]].describe())\n",
    "print(f\"\\nFraud vs Non-Fraud Comparison:\")\n",
    "print(train.groupby(\"isFraud\")[[\"identity_feature_count\", \"identity_missing_ratio\"]].mean())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91eb286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3H: C/D/M/V Aggregations\n",
      "============================================================\n",
      "âœ“ Created C_feature_count from 14 columns\n",
      "âœ“ Created D_feature_count from 17 columns\n",
      "âœ“ Created V_feature_count from 339 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3H: C/D/M/V Column Aggregations\n",
    "# Count non-null features in each group\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3H: C/D/M/V Aggregations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# C features (card-related metadata)\n",
    "c_cols = [c for c in train.columns if c.startswith(\"C\")]\n",
    "if c_cols:\n",
    "    train[\"C_feature_count\"] = train[c_cols].notna().sum(axis=1).astype(\"int8\")\n",
    "    print(f\"âœ“ Created C_feature_count from {len(c_cols)} columns\")\n",
    "\n",
    "# D features (timedelta features)\n",
    "d_cols = [c for c in train.columns if c.startswith(\"D\")]\n",
    "if d_cols:\n",
    "    train[\"D_feature_count\"] = train[d_cols].notna().sum(axis=1).astype(\"int8\")\n",
    "    print(f\"âœ“ Created D_feature_count from {len(d_cols)} columns\")\n",
    "\n",
    "# M features (match/mismatch features)\n",
    "m_cols = [c for c in train.columns if c.startswith(\"M\") and c not in [\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\"]]\n",
    "if m_cols:\n",
    "    train[\"M_feature_count\"] = train[m_cols].notna().sum(axis=1).astype(\"int8\")\n",
    "    print(f\"âœ“ Created M_feature_count from {len(m_cols)} columns\")\n",
    "\n",
    "# V features (Vesta engineered features)\n",
    "v_cols = [c for c in train.columns if c.startswith(\"V\")]\n",
    "if v_cols:\n",
    "    train[\"V_feature_count\"] = train[v_cols].notna().sum(axis=1).astype(\"int8\")\n",
    "    print(f\"âœ“ Created V_feature_count from {len(v_cols)} columns\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4990d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3I: Temporal Features\n",
      "============================================================\n",
      "âœ“ Created 6 temporal features\n",
      "\n",
      "Temporal Pattern Analysis:\n",
      "  Night transactions (0-5h): 24.16%\n",
      "  Morning peak (6-9h): 2.50%\n",
      "  Evening (18-23h): 42.04%\n",
      "  Weekend: 28.82%\n",
      "\n",
      "Fraud Rates by Time:\n",
      "  Night: 3.83%\n",
      "  Morning: 8.96%\n",
      "  Evening: 3.46%\n",
      "  Weekend: 3.38%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3I: Temporal Features\n",
    "# Time-based patterns reveal fraud timing strategies\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3I: Temporal Features\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Hour of day (0-23)\n",
    "train[\"TransactionHour\"] = ((train[\"TransactionDT\"] / 3600) % 24).astype(\"int8\")\n",
    "\n",
    "# Day of week (0=Monday, 6=Sunday)\n",
    "train[\"TransactionDayOfWeek\"] = ((train[\"TransactionDT\"] / 86400) % 7).astype(\"int8\")\n",
    "\n",
    "# Time period flags\n",
    "train[\"is_night_txn\"] = train[\"TransactionHour\"].between(0, 5).astype(\"int8\")\n",
    "train[\"is_morning_peak\"] = train[\"TransactionHour\"].between(6, 9).astype(\"int8\")\n",
    "train[\"is_evening\"] = train[\"TransactionHour\"].between(18, 23).astype(\"int8\")\n",
    "\n",
    "# Weekend flag\n",
    "train[\"is_weekend\"] = train[\"TransactionDayOfWeek\"].isin([5, 6]).astype(\"int8\")\n",
    "\n",
    "print(\"âœ“ Created 6 temporal features\")\n",
    "print(f\"\\nTemporal Pattern Analysis:\")\n",
    "print(f\"  Night transactions (0-5h): {train['is_night_txn'].mean():.2%}\")\n",
    "print(f\"  Morning peak (6-9h): {train['is_morning_peak'].mean():.2%}\")\n",
    "print(f\"  Evening (18-23h): {train['is_evening'].mean():.2%}\")\n",
    "print(f\"  Weekend: {train['is_weekend'].mean():.2%}\")\n",
    "\n",
    "print(f\"\\nFraud Rates by Time:\")\n",
    "print(f\"  Night: {train[train['is_night_txn']==1]['isFraud'].mean():.2%}\")\n",
    "print(f\"  Morning: {train[train['is_morning_peak']==1]['isFraud'].mean():.2%}\")\n",
    "print(f\"  Evening: {train[train['is_evening']==1]['isFraud'].mean():.2%}\")\n",
    "print(f\"  Weekend: {train[train['is_weekend']==1]['isFraud'].mean():.2%}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23de91de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3J: Feature Engineering Summary\n",
      "============================================================\n",
      "Total new features created: 24\n",
      "Final dataset shape: (590540, 458)\n",
      "\n",
      "Feature Categories:\n",
      "  Transaction Amount: 3\n",
      "  Card: 4\n",
      "  Address: 1\n",
      "  Device: 2\n",
      "  Email: 3\n",
      "  Identity: 2\n",
      "  C/D/M/V Aggregations: 4\n",
      "  Temporal: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3J: Feature Summary\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3J: Feature Engineering Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "new_features = [\n",
    "    \"log_transaction_amt\", \"is_low_amt\", \"is_high_amt\",\n",
    "    \"card_combo\", \"has_card2\", \"has_card3\", \"has_card5\",\n",
    "    \"addr_mismatch\",\n",
    "    \"has_device_type\", \"has_device_info\",\n",
    "    \"has_P_email\", \"has_R_email\", \"email_domain_match\",\n",
    "    \"identity_feature_count\", \"identity_missing_ratio\",\n",
    "    \"C_feature_count\", \"D_feature_count\", \"M_feature_count\", \"V_feature_count\",\n",
    "    \"TransactionHour\", \"TransactionDayOfWeek\",\n",
    "    \"is_night_txn\", \"is_morning_peak\", \"is_evening\", \"is_weekend\"\n",
    "]\n",
    "\n",
    "# Count actually created features\n",
    "created_features = [f for f in new_features if f in train.columns]\n",
    "\n",
    "print(f\"Total new features created: {len(created_features)}\")\n",
    "print(f\"Final dataset shape: {train.shape}\")\n",
    "print(f\"\\nFeature Categories:\")\n",
    "print(f\"  Transaction Amount: 3\")\n",
    "print(f\"  Card: 4\")\n",
    "print(f\"  Address: 1\")\n",
    "print(f\"  Device: 2\")\n",
    "print(f\"  Email: 3\")\n",
    "print(f\"  Identity: 2\")\n",
    "print(f\"  C/D/M/V Aggregations: 4\")\n",
    "print(f\"  Temporal: 6\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3171a453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3K: Data Quality Check\n",
      "============================================================\n",
      "âœ“ No missing values in new features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3K: Data Quality Check\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3K: Data Quality Check\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_counts = train[created_features].isna().sum()\n",
    "if missing_counts.sum() > 0:\n",
    "    print(\"Features with missing values:\")\n",
    "    print(missing_counts[missing_counts > 0])\n",
    "else:\n",
    "    print(\"âœ“ No missing values in new features\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68711c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3L: Dataset Saved\n",
      "============================================================\n",
      "âœ“ Saved to: ../data/processed/train_features_v1.parquet\n",
      "âœ“ Shape: (590540, 458)\n",
      "âœ“ New features: 24\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¯ Step 3 completed successfully!\n",
      "   Next: Step 4 - Data Preparation & Entity Behavioral Risk Encoding\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 3L: Save Feature-Enhanced Dataset\n",
    "\n",
    "output_path = \"../data/processed/train_features_v1.parquet\"\n",
    "train.to_parquet(output_path, index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3L: Dataset Saved\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"âœ“ Saved to: {output_path}\")\n",
    "print(f\"âœ“ Shape: {train.shape}\")\n",
    "print(f\"âœ“ New features: {len(created_features)}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nðŸŽ¯ Step 3 completed successfully!\")\n",
    "print(\"   Next: Step 4 - Data Preparation & Entity Behavioral Risk Encoding\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
